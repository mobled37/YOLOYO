{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILENAME_DIR = '/Users/valleotb/Desktop/Valleotb/sample_filename/metadata.csv'\n",
    "ANNOTATION_DIR = '/Users/valleotb/Desktop/Valleotb/sample_metadata'\n",
    "AUDIO_DIR = '/Users/valleotb/Desktop/Valleotb/sample_save'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/valleotb/Desktop/Valleotb/sample_save/200001_5632_25088.wav\n"
     ]
    }
   ],
   "source": [
    "filename_csv = pd.read_csv(FILENAME_DIR)\n",
    "audio_path = os.path.join(AUDIO_DIR, filename_csv.iloc[0][0])\n",
    "print(audio_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5125\n",
      "[5125, 6150, 7175, 8200, 9225, 10250, 11275, 12300, 13325, 14350, 15375, 16400, 17425, 18450, 19475, 20500, 21525, 22550, 23575]\n"
     ]
    }
   ],
   "source": [
    "annotation_path = os.path.join(ANNOTATION_DIR, filename_csv.iloc[0][1])\n",
    "data_list = pd.read_json(annotation_path)\n",
    "print(data_list['speech_segments'][0]['start_time'])\n",
    "start_time_list = []\n",
    "for idx in range(len(data_list)):\n",
    "    start_time_list.append(data_list['speech_segments'][idx]['start_time'])\n",
    "\n",
    "print(start_time_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'time': tensor([ 5125.,  6150.,  7175.,  8200.,  9225., 10250., 11275., 12300., 13325.,\n",
      "        14350., 15375., 16400., 17425., 18450., 19475., 20500., 21525., 22550.,\n",
      "        23575.]), 'label': tensor(1.)}, {'time': tensor([24600., 25625., 26650., 27675., 28700., 29725., 30750., 31775., 32800.,\n",
      "        33825., 34850., 35875., 36900., 37925., 38950., 39975.]), 'label': tensor(1.)}, {'time': tensor([ 46125.,  47150.,  48175.,  49200.,  50225.,  51250.,  52275.,  53300.,\n",
      "         54325.,  55350.,  56375.,  57400.,  58425.,  59450.,  60475.,  61500.,\n",
      "         62525.,  63550.,  64575.,  65600.,  66625.,  67650.,  68675.,  69700.,\n",
      "         70725.,  71750.,  72775.,  73800.,  74825.,  75850.,  76875.,  77900.,\n",
      "         78925.,  79950.,  80975.,  82000.,  83025.,  84050.,  85075.,  86100.,\n",
      "         87125.,  88150.,  89175.,  90200.,  91225.,  92250.,  93275.,  94300.,\n",
      "         95325.,  96350.,  97375.,  98400.,  99425., 100450., 101475., 102500.,\n",
      "        103525.]), 'label': tensor(1.)}, {'time': tensor([110700., 111725., 112750., 113775., 114800., 115825., 116850., 117875.,\n",
      "        118900., 119925., 120950., 121975., 123000., 124025., 125050., 126075.,\n",
      "        127100., 128125., 129150.]), 'label': tensor(1.)}, {'time': tensor([130175., 131200., 132225., 133250., 134275., 135300., 136325., 137350.,\n",
      "        138375., 139400., 140425., 141450., 142475., 143500., 144525., 145550.,\n",
      "        146575., 147600., 148625., 149650., 150675., 151700., 152725., 153750.,\n",
      "        154775., 155800.]), 'label': tensor(1.)}, {'time': tensor([160925., 161950., 162975., 164000., 165025., 166050., 167075., 168100.,\n",
      "        169125., 170150., 171175.]), 'label': tensor(1.)}, {'time': tensor([172200., 173225., 174250., 175275., 176300., 177325., 178350., 179375.,\n",
      "        180400., 181425., 182450., 183475., 184500., 185525., 186550., 187575.,\n",
      "        188600., 189625., 190650., 191675., 192700.]), 'label': tensor(1.)}, {'time': tensor([ 6150.,  7175.,  8200.,  9225., 10250., 11275., 12300., 13325., 14350.,\n",
      "        15375., 16400., 17425., 18450., 19475., 20500., 21525., 22550., 23575.,\n",
      "        24600., 25625., 26650., 27675., 28700., 29725., 30750., 31775., 32800.,\n",
      "        33825., 34850., 35875., 36900., 37925., 38950., 39975., 41000., 42025.,\n",
      "        43050., 44075., 45100., 46125., 47150., 48175., 49200., 50225., 51250.,\n",
      "        52275.]), 'label': tensor(1.)}, {'time': tensor([56375., 57400., 58425., 59450., 60475., 61500., 62525., 63550., 64575.,\n",
      "        65600., 66625., 67650., 68675., 69700.]), 'label': tensor(1.)}, {'time': tensor([ 4100.,  5125.,  6150.,  7175.,  8200.,  9225., 10250., 11275., 12300.,\n",
      "        13325., 14350., 15375., 16400., 17425., 18450., 19475., 20500., 21525.,\n",
      "        22550.]), 'label': tensor(1.)}, {'time': tensor([24600., 25625., 26650., 27675., 28700., 29725., 30750., 31775., 32800.,\n",
      "        33825., 34850., 35875., 36900., 37925., 38950., 39975., 41000., 42025.,\n",
      "        43050., 44075., 45100., 46125., 47150., 48175., 49200., 50225., 51250.,\n",
      "        52275., 53300., 54325.]), 'label': tensor(1.)}, {'time': tensor([55350., 56375., 57400., 58425., 59450., 60475., 61500., 62525., 63550.,\n",
      "        64575., 65600., 66625., 67650., 68675., 69700.]), 'label': tensor(1.)}, {'time': tensor([71750., 72775., 73800., 74825., 75850., 76875., 77900., 78925.]), 'label': tensor(1.)}, {'time': tensor([80975., 82000., 83025., 84050., 85075.]), 'label': tensor(1.)}, {'time': tensor([ 99425., 100450., 101475., 102500., 103525., 104550., 105575., 106600.,\n",
      "        107625., 108650., 109675., 110700.]), 'label': tensor(1.)}, {'time': tensor([113775., 114800., 115825., 116850., 117875., 118900., 119925., 120950.,\n",
      "        121975., 123000., 124025., 125050., 126075.]), 'label': tensor(1.)}, {'time': tensor([133250., 134275., 135300., 136325., 137350., 138375., 139400., 140425.,\n",
      "        141450., 142475., 143500., 144525., 145550., 146575., 147600., 148625.,\n",
      "        149650., 150675., 151700., 152725., 153750., 154775., 155800., 156825.,\n",
      "        157850., 158875., 159900., 160925., 161950., 162975., 164000., 165025.,\n",
      "        166050., 167075., 168100., 169125., 170150., 171175., 172200., 173225.,\n",
      "        174250., 175275., 176300., 177325., 178350.]), 'label': tensor(1.)}, {'time': tensor([180400., 181425., 182450.]), 'label': tensor(1.)}, {'time': tensor([185525., 186550., 187575., 188600., 189625., 190650., 191675., 192700.,\n",
      "        193725., 194750., 195775., 196800., 197825., 198850., 199875., 200900.,\n",
      "        201925., 202950.]), 'label': tensor(1.)}, {'time': tensor([206025., 207050., 208075., 209100., 210125., 211150., 212175., 213200.]), 'label': tensor(1.)}]\n"
     ]
    }
   ],
   "source": [
    "start_time_list = []\n",
    "\n",
    "\n",
    "for i in range(len(filename_csv)):\n",
    "    annotation_path = os.path.join(ANNOTATION_DIR, filename_csv.iloc[i][1])\n",
    "    data_list = pd.read_json(annotation_path)\n",
    "    list2 = []\n",
    "    list3 = {}\n",
    "    for idx in range(len(data_list)):\n",
    "\n",
    "        list2.append(data_list['speech_segments'][idx]['start_time'])\n",
    "        list3[\"time\"] = torch.tensor(list2, dtype=torch.float32)\n",
    "        list3[\"label\"] = torch.tensor(1, dtype=torch.float32)\n",
    "\n",
    "    # labels = [1 for j in range(len(list2))]\n",
    "    # dataset = list(zip(list2,labels))\n",
    "    start_time_list.append(list3)\n",
    "print(start_time_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5125.,  6150.,  7175.,  8200.,  9225., 10250., 11275., 12300., 13325.,\n",
      "         14350., 15375., 16400., 17425., 18450., 19475., 20500., 21525., 22550.,\n",
      "         23575.]])\n",
      "tensor([[24600., 25625., 26650., 27675., 28700., 29725., 30750., 31775., 32800.,\n",
      "         33825., 34850., 35875., 36900., 37925., 38950., 39975.]])\n",
      "tensor([[ 46125.,  47150.,  48175.,  49200.,  50225.,  51250.,  52275.,  53300.,\n",
      "          54325.,  55350.,  56375.,  57400.,  58425.,  59450.,  60475.,  61500.,\n",
      "          62525.,  63550.,  64575.,  65600.,  66625.,  67650.,  68675.,  69700.,\n",
      "          70725.,  71750.,  72775.,  73800.,  74825.,  75850.,  76875.,  77900.,\n",
      "          78925.,  79950.,  80975.,  82000.,  83025.,  84050.,  85075.,  86100.,\n",
      "          87125.,  88150.,  89175.,  90200.,  91225.,  92250.,  93275.,  94300.,\n",
      "          95325.,  96350.,  97375.,  98400.,  99425., 100450., 101475., 102500.,\n",
      "         103525.]])\n",
      "tensor([[110700., 111725., 112750., 113775., 114800., 115825., 116850., 117875.,\n",
      "         118900., 119925., 120950., 121975., 123000., 124025., 125050., 126075.,\n",
      "         127100., 128125., 129150.]])\n",
      "tensor([[130175., 131200., 132225., 133250., 134275., 135300., 136325., 137350.,\n",
      "         138375., 139400., 140425., 141450., 142475., 143500., 144525., 145550.,\n",
      "         146575., 147600., 148625., 149650., 150675., 151700., 152725., 153750.,\n",
      "         154775., 155800.]])\n",
      "tensor([[160925., 161950., 162975., 164000., 165025., 166050., 167075., 168100.,\n",
      "         169125., 170150., 171175.]])\n",
      "tensor([[172200., 173225., 174250., 175275., 176300., 177325., 178350., 179375.,\n",
      "         180400., 181425., 182450., 183475., 184500., 185525., 186550., 187575.,\n",
      "         188600., 189625., 190650., 191675., 192700.]])\n",
      "tensor([[ 6150.,  7175.,  8200.,  9225., 10250., 11275., 12300., 13325., 14350.,\n",
      "         15375., 16400., 17425., 18450., 19475., 20500., 21525., 22550., 23575.,\n",
      "         24600., 25625., 26650., 27675., 28700., 29725., 30750., 31775., 32800.,\n",
      "         33825., 34850., 35875., 36900., 37925., 38950., 39975., 41000., 42025.,\n",
      "         43050., 44075., 45100., 46125., 47150., 48175., 49200., 50225., 51250.,\n",
      "         52275.]])\n",
      "tensor([[56375., 57400., 58425., 59450., 60475., 61500., 62525., 63550., 64575.,\n",
      "         65600., 66625., 67650., 68675., 69700.]])\n",
      "tensor([[ 4100.,  5125.,  6150.,  7175.,  8200.,  9225., 10250., 11275., 12300.,\n",
      "         13325., 14350., 15375., 16400., 17425., 18450., 19475., 20500., 21525.,\n",
      "         22550.]])\n",
      "tensor([[24600., 25625., 26650., 27675., 28700., 29725., 30750., 31775., 32800.,\n",
      "         33825., 34850., 35875., 36900., 37925., 38950., 39975., 41000., 42025.,\n",
      "         43050., 44075., 45100., 46125., 47150., 48175., 49200., 50225., 51250.,\n",
      "         52275., 53300., 54325.]])\n",
      "tensor([[55350., 56375., 57400., 58425., 59450., 60475., 61500., 62525., 63550.,\n",
      "         64575., 65600., 66625., 67650., 68675., 69700.]])\n",
      "tensor([[71750., 72775., 73800., 74825., 75850., 76875., 77900., 78925.]])\n",
      "tensor([[80975., 82000., 83025., 84050., 85075.]])\n",
      "tensor([[ 99425., 100450., 101475., 102500., 103525., 104550., 105575., 106600.,\n",
      "         107625., 108650., 109675., 110700.]])\n",
      "tensor([[113775., 114800., 115825., 116850., 117875., 118900., 119925., 120950.,\n",
      "         121975., 123000., 124025., 125050., 126075.]])\n",
      "tensor([[133250., 134275., 135300., 136325., 137350., 138375., 139400., 140425.,\n",
      "         141450., 142475., 143500., 144525., 145550., 146575., 147600., 148625.,\n",
      "         149650., 150675., 151700., 152725., 153750., 154775., 155800., 156825.,\n",
      "         157850., 158875., 159900., 160925., 161950., 162975., 164000., 165025.,\n",
      "         166050., 167075., 168100., 169125., 170150., 171175., 172200., 173225.,\n",
      "         174250., 175275., 176300., 177325., 178350.]])\n",
      "tensor([[180400., 181425., 182450.]])\n",
      "tensor([[185525., 186550., 187575., 188600., 189625., 190650., 191675., 192700.,\n",
      "         193725., 194750., 195775., 196800., 197825., 198850., 199875., 200900.,\n",
      "         201925., 202950.]])\n",
      "tensor([[206025., 207050., 208075., 209100., 210125., 211150., 212175., 213200.]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = torch.utils.data.DataLoader(start_time_list, batch_size=1)\n",
    "\n",
    "for data in dataloader:\n",
    "    print(data['time'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 46125.,  47150.,  48175.,  ..., 101475., 102500., 103525.],\n",
      "        [130175., 131200., 132225.,  ...,      0.,      0.,      0.],\n",
      "        [172200., 173225., 174250.,  ...,      0.,      0.,      0.],\n",
      "        ...,\n",
      "        [ 24600.,  25625.,  26650.,  ...,      0.,      0.,      0.],\n",
      "        [ 99425., 100450., 101475.,  ...,      0.,      0.,      0.],\n",
      "        [185525., 186550., 187575.,  ...,      0.,      0.,      0.]]) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n"
     ]
    }
   ],
   "source": [
    "def make_batch(samples) :\n",
    "    inputs = [sample['time'] for sample in samples]\n",
    "    labels = [sample['label'] for sample in samples]\n",
    "    padded_inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True)\n",
    "    return {'input': padded_inputs.contiguous(),\n",
    "            'label': torch.stack(labels).contiguous()}\n",
    "\n",
    "sampler = torch.utils.data.RandomSampler(start_time_list)\n",
    "batch_sampler = torch.utils.data.BatchSampler(sampler,len(start_time_list),False)\n",
    "dataloader = torch.utils.data.DataLoader(start_time_list,batch_sampler=batch_sampler, collate_fn=make_batch)\n",
    "for data in dataloader:\n",
    "    print(data['input'], data['label'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5125, 16400,  8200, 14350, 11275,  7175, 12300, 19475, 20500, 22550,\n",
      "        18450,  9225, 17425, 15375, 13325,  6150, 21525, 23575, 10250]) tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "point_sampler = RandomSampler(dataset)\n",
    "batch_sampler = BatchSampler(point_sampler, 1024, False)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_sampler=batch_sampler)\n",
    "\n",
    "for data in dataloader:\n",
    "    print(data[0], data[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class VarMapDataset(Dataset):\n",
    "    def __len__(self):\n",
    "        return 10\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\"input\":torch.tensor([idx] * (idx+1),\n",
    "                                     dtype=torch.float32),\n",
    "                \"label\": torch.tensor(idx,\n",
    "                                      dtype=torch.float32)}\n",
    "\n",
    "var_map_dataset = VarMapDataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.]])\n",
      "tensor([[1., 1.]])\n",
      "tensor([[2., 2., 2.]])\n",
      "tensor([[3., 3., 3., 3.]])\n",
      "tensor([[4., 4., 4., 4., 4.]])\n",
      "tensor([[5., 5., 5., 5., 5., 5.]])\n",
      "tensor([[6., 6., 6., 6., 6., 6., 6.]])\n",
      "tensor([[7., 7., 7., 7., 7., 7., 7., 7.]])\n",
      "tensor([[8., 8., 8., 8., 8., 8., 8., 8., 8.]])\n",
      "tensor([[9., 9., 9., 9., 9., 9., 9., 9., 9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = torch.utils.data.DataLoader(var_map_dataset)\n",
    "for data in dataloader:\n",
    "    print(data['input'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [2., 2., 2.]]) tensor([0., 1., 2.])\n",
      "tensor([[3., 3., 3., 3., 0., 0.],\n",
      "        [4., 4., 4., 4., 4., 0.],\n",
      "        [5., 5., 5., 5., 5., 5.]]) tensor([3., 4., 5.])\n",
      "tensor([[6., 6., 6., 6., 6., 6., 6., 0., 0.],\n",
      "        [7., 7., 7., 7., 7., 7., 7., 7., 0.],\n",
      "        [8., 8., 8., 8., 8., 8., 8., 8., 8.]]) tensor([6., 7., 8.])\n",
      "tensor([[9., 9., 9., 9., 9., 9., 9., 9., 9., 9.]]) tensor([9.])\n"
     ]
    }
   ],
   "source": [
    "def make_batch(samples):\n",
    "    inputs = [sample['input'] for sample in samples]\n",
    "    labels = [sample['label'] for sample in samples]\n",
    "    padded_inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True)\n",
    "    return {'input': padded_inputs.contiguous(),\n",
    "            'label': torch.stack(labels).contiguous()}\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(var_map_dataset,\n",
    "                                         batch_size=3,\n",
    "                                         collate_fn=make_batch)\n",
    "for data in dataloader:\n",
    "    print(data['input'], data['label'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7., 7., 7., 7., 7., 7., 7., 7.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [4., 4., 4., 4., 4., 0., 0., 0.]]) tensor([7., 0., 4.])\n",
      "tensor([[1., 1., 0., 0., 0., 0.],\n",
      "        [5., 5., 5., 5., 5., 5.],\n",
      "        [2., 2., 2., 0., 0., 0.]]) tensor([1., 5., 2.])\n",
      "tensor([[8., 8., 8., 8., 8., 8., 8., 8., 8., 0.],\n",
      "        [9., 9., 9., 9., 9., 9., 9., 9., 9., 9.],\n",
      "        [6., 6., 6., 6., 6., 6., 6., 0., 0., 0.]]) tensor([8., 9., 6.])\n",
      "tensor([[3., 3., 3., 3.]]) tensor([3.])\n"
     ]
    }
   ],
   "source": [
    "sampler = RandomSampler(var_map_dataset)\n",
    "dataloader = torch.utils.data.DataLoader(var_map_dataset,\n",
    "                                         batch_size=3,\n",
    "                                         sampler=sampler,\n",
    "                                         collate_fn=make_batch)\n",
    "for data in dataloader:\n",
    "    print(data['input'], data['label'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483\n",
      "/Users/valleotb/Desktop/Valleotb/sample_save/200000_0_0.wav\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nfiles = os.listdir(path)\\nfor i in files :\\n    print(i)\\n'"
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUDIO_DIR = '/Users/valleotb/Desktop/Valleotb/sample_save'\n",
    "FILENAME_DIR = '/Users/valleotb/Desktop/Valleotb/sample_filename/metadata.csv'\n",
    "\n",
    "filename_csv = pd.read_csv(FILENAME_DIR)\n",
    "# print(filename_csv['audio_file'][1])\n",
    "print(len(filename_csv))\n",
    "\n",
    "path = os.path.join(filename_csv['audio_file'][0])\n",
    "print(path)\n",
    "print(path[-5])\n",
    "'''\n",
    "files = os.listdir(path)\n",
    "for i in files :\n",
    "    print(i)\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for inputs, targets in data_loader:\n",
    "    inputs, targets = inputs, targets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}